<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Голосовой Ассистент с WebRTC VAD</title>
    <style>
        body { 
            font-family: Arial, sans-serif; 
            max-width: 800px; 
            margin: 0 auto; 
            padding: 20px;
            background-color: #f5f5f5;
        }
        h1 {
            text-align: center;
            color: #333;
        }
        #micStatus { 
            width: 150px; height: 150px; 
            border-radius: 75px; 
            background-color: #4CAF50; 
            margin: 0 auto;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-size: 18px;
            text-align: center;
            transition: transform 0.1s, background-color 0.3s;
            box-shadow: 0 4px 8px rgba(0,0,0,0.2);
            cursor: pointer;
        }
        #micStatus.listening { background-color: #FF5722; }
        #micStatus.assistant-speaking { background-color: #2196F3; }
        #micStatus.disabled { background-color: #ccc; }
        
        #status, #transcript { 
            margin: 20px 0; 
            padding: 15px; 
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        #status {
            background-color: #e3f2fd;
            font-weight: bold;
            text-align: center;
        }
        #transcript {
            background-color: white;
            max-height: 300px;
            overflow-y: auto;
            line-height: 1.5;
        }
        .message {
            margin-bottom: 15px;
            padding-bottom: 15px;
            border-bottom: 1px solid #eee;
        }
        .user {
            color: #4CAF50;
            font-weight: bold;
        }
        .assistant {
            color: #2196F3;
            font-weight: bold;
        }
    </style>
</head>
<body>
    <h1>Голосовой Ассистент</h1>
    
    <div id="micStatus">Подключение...</div>
    
    <div id="status">Инициализация...</div>
    <div id="transcript">История диалога появится здесь</div>
    
    <!-- Подключаем WebRTC Voice Activity Detection (VAD) -->
    <script src="https://cdn.jsdelivr.net/npm/voice-activity-detection@0.0.5/voice-activity-detection.min.js"></script>
    
    <script>
        let socket;
        let mediaRecorder;
        let audioContext;
        let audioChunks = [];
        let isConnected = false;
        let stream;
        let isListening = false;
        let isSpeaking = false;
        let isAssistantSpeaking = false;
        let assistantAudio = null;
        let vad = null;
        
        // Время, после которого мы считаем, что пользователь закончил говорить (мс)
        const SILENCE_DURATION = 1500;
        let silenceTimer = null;
        
        // Время игнорирования звуков после остановки воспроизведения (мс)
        const IGNORE_AUDIO_AFTER_STOP = 500;
        let lastAudioStopTime = 0;
        
        // Элементы страницы
        const micStatusDiv = document.getElementById('micStatus');
        const statusDiv = document.getElementById('status');
        const transcriptDiv = document.getElementById('transcript');
        
        // Нажатие на индикатор микрофона для ручного включения/выключения
        micStatusDiv.addEventListener('click', toggleListening);
        
        // Автоматически подключаемся при загрузке страницы
        window.addEventListener('load', init);
        
        async function init() {
            connectWebSocket();
            await setupAudioProcessing();
        }
        
        function toggleListening() {
            if (!isConnected || !stream) return;
            
            if (isListening) {
                // Если слушаем, останавливаем
                stopListening();
                micStatusDiv.textContent = 'Нажмите для начала';
                statusDiv.textContent = 'Режим ожидания';
            } else {
                // Если не слушаем, начинаем
                startListening();
                micStatusDiv.textContent = 'Говорите';
                statusDiv.textContent = 'Готов к общению!';
            }
        }
        
        // Функция подключения к WebSocket
        function connectWebSocket() {
            // В продакшене замените на адрес вашего сервера
            // Для локальной разработки используйте "ws://localhost:8000/ws/demo"
            const wsProtocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsUrl = `${wsProtocol}//${window.location.host}/ws/demo`;
            
            socket = new WebSocket(wsUrl);
            
            socket.onopen = function() {
                statusDiv.textContent = 'Соединение установлено';
                isConnected = true;
                micStatusDiv.textContent = 'Подготовка...';
            };
            
            socket.onmessage = function(event) {
                if (event.data instanceof Blob) {
                    // Воспроизводим аудио от ассистента
                    playAssistantAudio(event.data);
                } else {
                    // Обрабатываем JSON сообщения
                    const data = JSON.parse(event.data);
                    console.log('Сообщение:', data.type);
                    
                    // Обработка статуса соединения
                    if (data.type === 'connection_status' && data.status === 'connected') {
                        statusDiv.textContent = 'Готов к общению!';
                        micStatusDiv.textContent = 'Говорите';
                        startListening();
                    }
                    
                    // Обработка транскрипций
                    if (data.type === 'conversation.item.input_audio_transcription.completed' && data.transcript) {
                        addToTranscript('user', data.transcript);
                    } else if (data.type === 'response.audio_transcript.done' && data.transcript) {
                        addToTranscript('assistant', data.transcript);
                    }
                    
                    // Обработка ошибок
                    if (data.type === 'error') {
                        statusDiv.textContent = `Ошибка: ${data.error.message}`;
                        console.error('Ошибка:', data.error);
                    }
                }
            };
            
            socket.onclose = function() {
                statusDiv.textContent = 'Соединение закрыто. Перезагрузите страницу.';
                isConnected = false;
                micStatusDiv.textContent = 'Отключено';
                micStatusDiv.classList.add('disabled');
                stopListening();
            };
            
            socket.onerror = function(error) {
                statusDiv.textContent = `Ошибка соединения`;
                console.error('WebSocket ошибка:', error);
            };
        }
        
        // Добавление сообщений в историю диалога
        function addToTranscript(role, text) {
            const messageDiv = document.createElement('div');
            messageDiv.className = 'message';
            
            const roleSpan = document.createElement('span');
            roleSpan.className = role;
            roleSpan.textContent = role === 'user' ? 'Вы: ' : 'Ассистент: ';
            
            messageDiv.appendChild(roleSpan);
            messageDiv.appendChild(document.createTextNode(text));
            
            // Вставляем новое сообщение в начало
            if (transcriptDiv.firstChild) {
                transcriptDiv.insertBefore(messageDiv, transcriptDiv.firstChild);
            } else {
                transcriptDiv.appendChild(messageDiv);
            }
        }
        
        // Настройка аудио обработки и WebRTC VAD
        async function setupAudioProcessing() {
            try {
                stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: { 
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    } 
                });
                
                // Создаем AudioContext для WebRTC VAD
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                
                // Опции для VAD
                const vadOptions = {
                    audioContext: audioContext,
                    source: audioContext.createMediaStreamSource(stream),
                    voice_stop: function() {
                        console.log('VAD: Голос остановлен');
                        // Если мы в процессе записи, останавливаем через небольшую задержку
                        if (isSpeaking && !silenceTimer) {
                            silenceTimer = setTimeout(() => {
                                stopRecording();
                                silenceTimer = null;
                            }, SILENCE_DURATION);
                        }
                    },
                    voice_start: function() {
                        console.log('VAD: Голос обнаружен');
                        
                        // Игнорируем звуки сразу после остановки воспроизведения
                        const now = Date.now();
                        if (now - lastAudioStopTime < IGNORE_AUDIO_AFTER_STOP) {
                            return;
                        }
                        
                        // Если ассистент говорит, прерываем его
                        if (isAssistantSpeaking) {
                            interruptAssistant();
                        }
                        
                        // Сбрасываем таймер тишины
                        if (silenceTimer) {
                            clearTimeout(silenceTimer);
                            silenceTimer = null;
                        }
                        
                        // Начинаем запись, если еще не начали
                        if (isListening && !isSpeaking) {
                            startRecording();
                        }
                    }
                };
                
                // Инициализируем VAD
                vad = new VAD(vadOptions);
                
                statusDiv.textContent = 'Микрофон подключен';
                
            } catch (error) {
                console.error('Ошибка доступа к микрофону:', error);
                statusDiv.textContent = `Нет доступа к микрофону`;
                micStatusDiv.textContent = 'Нет доступа';
                micStatusDiv.classList.add('disabled');
            }
        }
        
        // Функция начала прослушивания
        function startListening() {
            if (!isConnected || !stream || isListening) return;
            
            isListening = true;
            
            // Если используем VAD, включаем его
            if (vad) {
                vad.connect();
            }
            
            micStatusDiv.textContent = 'Говорите';
            statusDiv.textContent = 'Готов к общению!';
        }
        
        // Функция остановки прослушивания
        function stopListening() {
            isListening = false;
            
            // Останавливаем VAD
            if (vad) {
                vad.disconnect();
            }
            
            // Если запись активна, останавливаем её
            if (isSpeaking) {
                stopRecording();
            }
        }
        
        // Функция прерывания ответа ассистента
        function interruptAssistant() {
            console.log('Прерываем ассистента');
            
            // Останавливаем воспроизведение
            if (assistantAudio && !assistantAudio.paused) {
                assistantAudio.pause();
                assistantAudio = null;
            }
            
            // Отправляем команду отмены текущего ответа
            if (socket && socket.readyState === WebSocket.OPEN) {
                socket.send(JSON.stringify({
                    type: "response.cancel",
                    event_id: `cancel_${Date.now()}`
                }));
                console.log('Отправлена команда отмены ответа');
            }
            
            isAssistantSpeaking = false;
            micStatusDiv.classList.remove('assistant-speaking');
            micStatusDiv.textContent = 'Говорите';
        }
        
        // Функция начала записи
        function startRecording() {
            if (!isConnected || isSpeaking) return;
            
            try {
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];
                
                mediaRecorder.ondataavailable = function(event) {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                        
                        // Отправка аудио в WebSocket
                        const reader = new FileReader();
                        reader.onloadend = function() {
                            if (socket && socket.readyState === WebSocket.OPEN) {
                                const base64Audio = reader.result.split(',')[1];
                                socket.send(JSON.stringify({
                                    type: "input_audio_buffer.append",
                                    audio: base64Audio,
                                    event_id: `audio_${Date.now()}`
                                }));
                            }
                        };
                        reader.readAsDataURL(event.data);
                    }
                };
                
                mediaRecorder.start(100); // Отправляем чанки каждые 100мс
                isSpeaking = true;
                micStatusDiv.classList.add('listening');
                micStatusDiv.classList.remove('assistant-speaking');
                micStatusDiv.textContent = 'Слушаю...';
                statusDiv.textContent = 'Слушаю вас...';
            } catch (error) {
                console.error('Ошибка начала записи:', error);
                statusDiv.textContent = `Ошибка записи голоса`;
            }
        }
        
        // Функция остановки записи
        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                
                // Отправляем команду завершения ввода
                if (socket && socket.readyState === WebSocket.OPEN) {
                    socket.send(JSON.stringify({
                        type: "input_audio_buffer.commit",
                        event_id: `commit_${Date.now()}`
                    }));
                }
                
                isSpeaking = false;
                if (silenceTimer) {
                    clearTimeout(silenceTimer);
                    silenceTimer = null;
                }
                
                micStatusDiv.classList.remove('listening');
                micStatusDiv.textContent = 'Обрабатываю...';
                statusDiv.textContent = 'Обрабатываю...';
            }
        }
        
        // Функция воспроизведения аудио от ассистента
        function playAssistantAudio(audioBlob) {
            // Отмечаем, что ассистент начал говорить
            isAssistantSpeaking = true;
            micStatusDiv.classList.add('assistant-speaking');
            micStatusDiv.textContent = 'Ассистент говорит';
            statusDiv.textContent = 'Ассистент говорит...';
            
            const audioUrl = URL.createObjectURL(audioBlob);
            assistantAudio = new Audio(audioUrl);
            
            assistantAudio.onended = function() {
                URL.revokeObjectURL(audioUrl);
                isAssistantSpeaking = false;
                micStatusDiv.classList.remove('assistant-speaking');
                micStatusDiv.textContent = 'Говорите';
                statusDiv.textContent = 'Готов к общению!';
                
                // Запоминаем время остановки аудио для предотвращения ложных срабатываний
                lastAudioStopTime = Date.now();
            };
            
            assistantAudio.onpause = function() {
                // Запоминаем время остановки аудио для предотвращения ложных срабатываний
                lastAudioStopTime = Date.now();
            };
            
            assistantAudio.play();
        }
    </script>
</body>
</html>
