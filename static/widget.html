<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>WellcomeAI Widget</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
      font-family: 'Segoe UI', 'Roboto', sans-serif;
    }
    
    html, body {
      width: 100%;
      height: 100%;
      overflow: hidden;
      background: transparent;
    }
    
    /* Основной контейнер виджета - фиксированное позиционирование */
    #wellcomeAiContainer {
      position: fixed;
      bottom: 20px;
      right: 20px;
      z-index: 999999;
      font-family: 'Segoe UI', 'Roboto', sans-serif;
    }
    
    /* Кнопка-робот */
    .robot-button {
      width: 70px;
      height: 70px;
      border-radius: 50%;
      background: linear-gradient(135deg, #4a86e8, #2965c7);
      box-shadow: 0 3px 10px rgba(0, 0, 0, 0.3);
      display: flex;
      align-items: center;
      justify-content: center;
      cursor: pointer;
      position: relative;
      overflow: hidden;
      transition: transform 0.3s ease;
    }
    
    .robot-button:hover {
      transform: scale(1.05);
    }
    
    .robot-button::before {
      content: '';
      position: absolute;
      width: 140%;
      height: 140%;
      background: linear-gradient(45deg, rgba(255, 255, 255, 0.3), rgba(74, 134, 232, 0.2));
      animation: wave 8s linear infinite;
      border-radius: 40%;
    }
    
    @keyframes wave {
      0% { transform: rotate(0deg); }
      100% { transform: rotate(360deg); }
    }
    
    .robot-icon {
      color: white;
      font-size: 32px;
      z-index: 2;
    }
    
    /* Чат-окно */
    .chat-window {
      position: fixed;
      bottom: 30px;
      right: 30px;
      width: 350px;
      height: 500px;
      background-color: white;
      border-radius: 15px;
      box-shadow: 0 5px 25px rgba(0, 0, 0, 0.3);
      display: none;
      flex-direction: column;
      overflow: hidden;
      z-index: 999999;
    }
    
    .chat-window.active {
      display: flex;
    }
    
    /* Заголовок чата */
    .chat-header {
      display: flex;
      align-items: center;
      justify-content: space-between;
      padding: 15px;
      background: linear-gradient(135deg, #4a86e8, #2965c7);
      color: white;
    }
    
    .chat-title {
      font-weight: 600;
      font-size: 16px;
      display: flex;
      align-items: center;
      gap: 10px;
    }
    
    .close-button {
      background: none;
      border: none;
      color: white;
      font-size: 18px;
      cursor: pointer;
      opacity: 0.8;
      transition: opacity 0.2s;
    }
    
    .close-button:hover {
      opacity: 1;
    }
    
    /* Основное содержимое чата */
    .chat-content {
      flex: 1;
      display: flex;
      flex-direction: column;
      justify-content: center;
      align-items: center;
      padding: 20px;
      position: relative;
    }
    
    /* Сообщения */
    .messages-container {
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      bottom: 80px;
      padding: 15px;
      overflow-y: auto;
      display: flex;
      flex-direction: column;
      gap: 10px;
    }
    
    .message {
      max-width: 80%;
      padding: 10px 15px;
      border-radius: 15px;
      word-break: break-word;
      animation: fadeIn 0.3s ease;
    }
    
    @keyframes fadeIn {
      from { opacity: 0; transform: translateY(10px); }
      to { opacity: 1; transform: translateY(0); }
    }
    
    .message.assistant {
      align-self: flex-start;
      background-color: #F1F5F9;
      border-bottom-left-radius: 5px;
    }
    
    .message.user {
      align-self: flex-end;
      background-color: #E6F2FF;
      color: #0A51A1;
      border-bottom-right-radius: 5px;
    }
    
    /* Круг голосового помощника */
    .voice-circle {
      width: 120px;
      height: 120px;
      border-radius: 50%;
      background: linear-gradient(135deg, #ffffff, #e1f5fe, #4a86e8);
      box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
      position: relative;
      overflow: hidden;
      display: flex;
      align-items: center;
      justify-content: center;
      transition: all 0.3s ease;
      z-index: 5;
      cursor: pointer;
    }
    
    .voice-circle::before {
      content: '';
      position: absolute;
      width: 140%;
      height: 140%;
      background: linear-gradient(45deg, rgba(255, 255, 255, 0.3), rgba(74, 134, 232, 0.2));
      animation: wave 8s linear infinite;
      border-radius: 40%;
    }
    
    /* Состояние прослушивания */
    .voice-circle.listening {
      background: linear-gradient(135deg, #ffffff, #e3f2fd, #2196f3);
      box-shadow: 0 0 30px rgba(33, 150, 243, 0.6);
    }
    
    .voice-circle.listening::before {
      animation: wave 4s linear infinite;
      background: linear-gradient(45deg, rgba(255, 255, 255, 0.5), rgba(33, 150, 243, 0.3));
    }
    
    .voice-circle.listening::after {
      content: '';
      position: absolute;
      width: 100%;
      height: 100%;
      border-radius: 50%;
      border: 3px solid rgba(33, 150, 243, 0.5);
      animation: pulse 1.5s ease-out infinite;
    }
    
    @keyframes pulse {
      0% { transform: scale(0.95); opacity: 0.7; }
      50% { transform: scale(1.05); opacity: 0.3; }
      100% { transform: scale(0.95); opacity: 0.7; }
    }
    
    /* Состояние говорения */
    .voice-circle.speaking {
      background: linear-gradient(135deg, #ffffff, #e8f5e9, #4caf50);
      box-shadow: 0 0 30px rgba(76, 175, 80, 0.6);
    }
    
    .voice-circle.speaking::before {
      animation: wave 3s linear infinite;
      background: linear-gradient(45deg, rgba(255, 255, 255, 0.5), rgba(76, 175, 80, 0.3));
    }
    
    .voice-circle.speaking::after {
      content: '';
      position: absolute;
      width: 100%;
      height: 100%;
      background: radial-gradient(circle, transparent 50%, rgba(76, 175, 80, 0.1) 100%);
      border-radius: 50%;
      animation: ripple 2s ease-out infinite;
    }
    
    @keyframes ripple {
      0% { transform: scale(0.8); opacity: 0; }
      50% { opacity: 0.5; }
      100% { transform: scale(1.2); opacity: 0; }
    }
    
    .mic-icon {
      font-size: 32px;
      color: #4a86e8;
      z-index: 10;
    }
    
    .voice-circle.listening .mic-icon {
      color: #2196f3;
    }
    
    .voice-circle.speaking .mic-icon {
      color: #4caf50;
    }
    
    /* Подсказка */
    .hint-text {
      margin-top: 20px;
      text-align: center;
      color: #777;
      font-size: 14px;
    }
    
    /* Аудио визуализация */
    .audio-visualization {
      position: absolute;
      width: 100%;
      max-width: 200px;
      height: 40px;
      bottom: 20px;
      opacity: 0.8;
    }
    
    .audio-bars {
      display: flex;
      align-items: flex-end;
      height: 30px;
      gap: 2px;
      width: 100%;
      justify-content: center;
    }
    
    .audio-bar {
      width: 3px;
      height: 2px;
      background-color: #4a86e8;
      border-radius: 1px;
      transition: height 0.1s ease;
    }
    
    /* Модальное окно загрузки */
    .loader-modal {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background-color: rgba(255, 255, 255, 0.8);
      display: flex;
      align-items: center;
      justify-content: center;
      z-index: 1000;
      opacity: 0;
      visibility: hidden;
      transition: all 0.3s;
      border-radius: 15px;
    }
    
    .loader-modal.active {
      opacity: 1;
      visibility: visible;
    }
    
    .loader {
      width: 40px;
      height: 40px;
      border: 3px solid rgba(74, 134, 232, 0.3);
      border-radius: 50%;
      border-top-color: #4a86e8;
      animation: spin 1s linear infinite;
    }
    
    @keyframes spin {
      to { transform: rotate(360deg); }
    }
    
    /* Мобильная адаптация */
    @media (max-width: 480px) {
      .chat-window {
        width: 300px;
        height: 450px;
        bottom: 20px;
        right: 20px;
      }
      
      .voice-circle {
        width: 100px;
        height: 100px;
      }
      
      .mic-icon {
        font-size: 28px;
      }
    }
  </style>
</head>
<body>
  <!-- Основной контейнер виджета -->
  <div id="wellcomeAiContainer">
    <!-- Кнопка-робот -->
    <div class="robot-button" id="robotButton">
      <i class="fas fa-robot robot-icon"></i>
    </div>
    
    <!-- Чат-окно -->
    <div class="chat-window" id="chatWindow">
      <!-- Заголовок -->
      <div class="chat-header">
        <div class="chat-title">
          <i class="fas fa-robot robot-icon"></i>
          <span>WellcomeAI Ассистент</span>
        </div>
        <button class="close-button" id="closeButton">
          <i class="fas fa-times"></i>
        </button>
      </div>
      
      <!-- Основное содержимое -->
      <div class="chat-content">
        <!-- Контейнер сообщений -->
        <div class="messages-container" id="messagesContainer"></div>
        
        <!-- Круг голосового ассистента -->
        <div class="voice-circle" id="voiceCircle">
          <i class="fas fa-microphone mic-icon"></i>
        </div>
        
        <!-- Подсказка -->
        <div class="hint-text" id="hintText">Нажмите на круг, чтобы начать говорить</div>
        
        <!-- Аудио визуализация -->
        <div class="audio-visualization" id="audioVisualization">
          <div class="audio-bars" id="audioBars"></div>
        </div>
      </div>
      
      <!-- Модальное окно загрузки -->
      <div class="loader-modal" id="loaderModal">
        <div class="loader"></div>
      </div>
    </div>
  </div>

  <script>
    // Проверка, находимся ли мы в iframe
    function isInIframe() { try { return window.self !== window.top; } catch (e) { return true; } }

    // Элементы UI
    const container = document.getElementById('wellcomeAiContainer');
    const robotButton = document.getElementById('robotButton');
    const chatWindow = document.getElementById('chatWindow');
    const closeButton = document.getElementById('closeButton');
    const voiceCircle = document.getElementById('voiceCircle');
    const messagesContainer = document.getElementById('messagesContainer');
    const hintText = document.getElementById('hintText');
    const audioBars = document.getElementById('audioBars');
    const loaderModal = document.getElementById('loaderModal');
    
    // Переменные для обработки аудио
    let audioChunksBuffer = [];
    let audioPlaybackQueue = [];
    let isPlayingAudio = false;
    let hasAudioData = false;
    let audioDataStartTime = 0;
    let minimumAudioLength = 300;
    let reconnecting = false;
    let isListening = false;
    let websocket = null;
    let audioContext = null;
    let mediaStream = null;
    let audioProcessor = null;
    let isConnected = false;
    let widgetMode = 'compact'; // 'compact' или 'expanded'
    let messageHistory = [];
    
    // Конфигурация для оптимизации потока аудио
    const AUDIO_CONFIG = {
      silenceThreshold: 0.01,
      silenceDuration: 300,
      bufferCheckInterval: 50,
      soundDetectionThreshold: 0.02
    };
    
    // Функция логирования
    function log(message, level = 'info') {
      const timestamp = new Date().toLocaleTimeString();
      console.log(`[${level.toUpperCase()}] ${message}`);
    }
    
    // Показать сообщение в чате
    function addMessage(text, isUser = false) {
      const messageElement = document.createElement('div');
      messageElement.className = `message ${isUser ? 'user' : 'assistant'}`;
      messageElement.textContent = text;
      messagesContainer.appendChild(messageElement);
      
      // Прокручиваем к последнему сообщению
      messagesContainer.scrollTop = messagesContainer.scrollHeight;
      
      // Сохраняем сообщение в истории
      messageHistory.push({
        type: isUser ? 'user' : 'assistant',
        text: text
      });
    }
    
    // Переключение между компактным и развернутым режимом
    function toggleWidgetMode() {
      if (widgetMode === 'compact') {
        expandWidget();
      } else {
        collapseWidget();
      }
    }
    
    // Разворачиваем виджет
    function expandWidget() {
      // Скрываем кнопку робота
      robotButton.style.display = 'none';
      
      // Показываем окно чата
      chatWindow.classList.add('active');
      
      widgetMode = 'expanded';
      
      // Если нет сообщений и соединение установлено, добавляем приветствие
      if (messageHistory.length === 0 && isConnected) {
        setTimeout(() => {
          addMessage('Привет! Я голосовой ассистент WellcomeAI. Чем могу помочь?');
          // Начинаем слушать, если мы не слушаем уже
          if (!isListening && !isPlayingAudio) {
            startListening();
          }
        }, 500);
      }
    }
    
    // Сворачиваем виджет
    function collapseWidget() {
      // Показываем кнопку робота
      robotButton.style.display = 'flex';
      
      // Скрываем окно чата
      chatWindow.classList.remove('active');
      
      widgetMode = 'compact';
    }
    
    // Создаем аудио-бары для визуализации
    function createAudioBars(count = 15) {
      audioBars.innerHTML = '';
      for (let i = 0; i < count; i++) {
        const bar = document.createElement('div');
        bar.className = 'audio-bar';
        audioBars.appendChild(bar);
      }
    }
    createAudioBars();
    
    // Инициализация микрофона и AudioContext
    async function initAudio() {
      try {
        log("Запрос разрешения на доступ к микрофону...");
        
        // Проверяем поддержку getUserMedia
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
          throw new Error("Ваш браузер не поддерживает доступ к микрофону");
        }
        
        // Запрашиваем доступ к микрофону с оптимальными настройками
        mediaStream = await navigator.mediaDevices.getUserMedia({ 
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
            sampleRate: 24000
          } 
        });
        
        log("Доступ к микрофону получен");
        
        // Создаем AudioContext с нужной частотой дискретизации
        audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
        log(`AudioContext создан с частотой ${audioContext.sampleRate} Гц`);
        
        // Создаем обработчик аудиопотока
        const streamSource = audioContext.createMediaStreamSource(mediaStream);
        
        // Выбираем размер буфера
        const bufferSize = 2048; // Меньший размер буфера для меньшей задержки
        
        // Проверяем, доступен ли ScriptProcessorNode
        if (audioContext.createScriptProcessor) {
          audioProcessor = audioContext.createScriptProcessor(bufferSize, 1, 1);
          log("Создан ScriptProcessorNode для обработки аудио");
        } else {
          throw new Error("Ваш браузер не поддерживает ScriptProcessorNode");
        }
        
        // Переменные для отслеживания звука
        let isSilent = true;
        let silenceStartTime = Date.now();
        let lastCommitTime = 0;
        let hasSentAudioInCurrentSegment = false;
        
        // Обработчик аудио с оптимизированной логикой
        audioProcessor.onaudioprocess = function(e) {
          if (isListening && websocket && websocket.readyState === WebSocket.OPEN && !reconnecting) {
            // Получаем данные с микрофона
            const inputData = e.inputBuffer.getChannelData(0);
            
            // Вычисляем максимальную амплитуду
            let maxAmplitude = 0;
            for (let i = 0; i < inputData.length; i++) {
              const absValue = Math.abs(inputData[i]);
              maxAmplitude = Math.max(maxAmplitude, absValue);
            }
            
            // Определяем, есть ли звук
            const hasSound = maxAmplitude > AUDIO_CONFIG.soundDetectionThreshold;
            
            // Обновляем визуализацию
            updateAudioVisualization(inputData);
            
            // Преобразуем float32 в int16
            const pcm16Data = new Int16Array(inputData.length);
            for (let i = 0; i < inputData.length; i++) {
              pcm16Data[i] = Math.max(-32768, Math.min(32767, Math.floor(inputData[i] * 32767)));
            }
            
            // Отправляем данные через WebSocket
            try {
              const message = JSON.stringify({
                type: "input_audio_buffer.append",
                event_id: `audio_${Date.now()}`,
                audio: arrayBufferToBase64(pcm16Data.buffer)
              });
              
              websocket.send(message);
              hasSentAudioInCurrentSegment = true;
              
              // Отмечаем наличие аудиоданных
              if (!hasAudioData && hasSound) {
                hasAudioData = true;
                audioDataStartTime = Date.now();
                log("Начало записи аудиоданных");
                
                // Заменяем подсказку
                hintText.textContent = "Говорите...";
              }
              
            } catch (error) {
              log(`Ошибка отправки аудио: ${error.message}`, "error");
            }
            
            // Логика определения тишины и автоматической отправки
            const now = Date.now();
            
            if (hasSound) {
              // Сбрасываем время начала тишины
              isSilent = false;
              silenceStartTime = now;
              
              // Активируем визуальное состояние прослушивания
              if (!voiceCircle.classList.contains('listening') && 
                  !voiceCircle.classList.contains('speaking')) {
                voiceCircle.classList.add('listening');
              }
            } else if (!isSilent) {
              // Если наступила тишина
              const silenceDuration = now - silenceStartTime;
              
              if (silenceDuration > AUDIO_CONFIG.silenceDuration) {
                isSilent = true;
                
                // Если прошло достаточно времени с последней отправки и были данные
                if (now - lastCommitTime > 1000 && hasSentAudioInCurrentSegment) {
                  // Отправляем буфер с задержкой 
                  setTimeout(() => {
                    // Проверяем снова, не появился ли звук
                    if (isSilent && isListening && !reconnecting) {
                      commitAudioBuffer();
                      lastCommitTime = Date.now();
                      hasSentAudioInCurrentSegment = false;
                    }
                  }, 100);
                }
              }
            }
          }
        };
        
        // Подключаем обработчик
        streamSource.connect(audioProcessor);
        audioProcessor.connect(audioContext.destination);
        
        log("Аудио инициализировано успешно");
        return true;
      } catch (error) {
        log(`Ошибка инициализации аудио: ${error.message}`, "error");
        addMessage("Ошибка доступа к микрофону. Проверьте настройки браузера.");
        return false;
      }
    }
    
    // Функция для отправки аудиобуфера
    function commitAudioBuffer() {
      if (!isListening || !websocket || websocket.readyState !== WebSocket.OPEN || reconnecting) return;
      
      // Проверяем, есть ли в буфере достаточно аудиоданных
      if (!hasAudioData) {
        log("Не отправляем пустой аудиобуфер", "warn");
        return;
      }
      
      // Проверяем минимальную длительность аудио (300мс требуется для корректной работы)
      const audioLength = Date.now() - audioDataStartTime;
      if (audioLength < minimumAudioLength) {
        log(`Аудиобуфер слишком короткий (${audioLength}мс), ожидаем больше данных`, "warn");
        
        // Продолжаем запись еще немного времени
        setTimeout(() => {
          // Повторно пытаемся отправить буфер
          if (isListening && hasAudioData && !reconnecting) {
            log(`Отправка аудиобуфера после дополнительной записи (${Date.now() - audioDataStartTime}мс)`);
            sendCommitBuffer();
          }
        }, minimumAudioLength - audioLength + 50); // Добавляем небольшой запас
        
        return;
      }
      
      // Если все проверки пройдены, отправляем буфер
      sendCommitBuffer();
    }
    
    // Функция для фактической отправки буфера
    function sendCommitBuffer() {
      log("Отправка аудиобуфера");
      
      // Сбрасываем эффект активности
      voiceCircle.classList.remove('listening');
      
      // Обновляем подсказку
      hintText.textContent = "Обработка...";
      
      // Отправляем команду для завершения буфера
      websocket.send(JSON.stringify({
        type: "input_audio_buffer.commit",
        event_id: `commit_${Date.now()}`
      }));
      
      // Сбрасываем флаги
      isListening = false;
      hasAudioData = false;
      audioDataStartTime = 0;
    }
    
    // Преобразование ArrayBuffer в Base64
    function arrayBufferToBase64(buffer) {
      const bytes = new Uint8Array(buffer);
      let binary = '';
      for (let i = 0; i < bytes.byteLength; i++) {
        binary += String.fromCharCode(bytes[i]);
      }
      return btoa(binary);
    }
    
    // Преобразование Base64 в ArrayBuffer
    function base64ToArrayBuffer(base64) {
      try {
        const binaryString = atob(base64);
        const bytes = new Uint8Array(binaryString.length);
        for (let i = 0; i < binaryString.length; i++) {
          bytes[i] = binaryString.charCodeAt(i);
        }
        return bytes.buffer;
      } catch (e) {
        log(`Ошибка при декодировании base64: ${e.message}`, "error");
        return new ArrayBuffer(0);
      }
    }
    
    // Обновление визуализации аудио
    function updateAudioVisualization(audioData) {
      const bars = audioBars.querySelectorAll('.audio-bar');
      const step = Math.floor(audioData.length / bars.length);
      
      for (let i = 0; i < bars.length; i++) {
        // Вычисляем среднее значение амплитуды для этого "отрезка" аудиоданных
        let sum = 0;
        for (let j = 0; j < step; j++) {
          const index = i * step + j;
          if (index < audioData.length) {
            sum += Math.abs(audioData[index]);
          }
        }
        const average = sum / step;
        
        // Нормализуем значение для высоты полосы (от 2px до 30px)
        const height = 2 + Math.min(28, Math.floor(average * 100));
        bars[i].style.height = `${height}px`;
      }
    }
    
    // Сброс визуализации аудио
    function resetAudioVisualization() {
      const bars = audioBars.querySelectorAll('.audio-bar');
      bars.forEach(bar => {
        bar.style.height = '2px';
      });
    }
    
    // Создаём простой WAV из PCM данных
    function createWavFromPcm(pcmBuffer, sampleRate = 24000) {
      // Создаём заголовок WAV
      const wavHeader = new ArrayBuffer(44);
      const view = new DataView(wavHeader);
      
      // "RIFF" chunk descriptor
      view.setUint8(0, 'R'.charCodeAt(0));
      view.setUint8(1, 'I'.charCodeAt(0));
      view.setUint8(2, 'F'.charCodeAt(0));
      view.setUint8(3, 'F'.charCodeAt(0));
      
      view.setUint32(4, 36 + pcmBuffer.byteLength, true); // Размер всего файла - 8
      
      // "WAVE" формат
      view.setUint8(8, 'W'.charCodeAt(0));
      view.setUint8(9, 'A'.charCodeAt(0));
      view.setUint8(10, 'V'.charCodeAt(0));
      view.setUint8(11, 'E'.charCodeAt(0));
      
      // "fmt " субчанк
      view.setUint8(12, 'f'.charCodeAt(0));
      view.setUint8(13, 'm'.charCodeAt(0));
      view.setUint8(14, 't'.charCodeAt(0));
      view.setUint8(15, ' '.charCodeAt(0));
      
      view.setUint32(16, 16, true); // Размер fmt субчанка
      view.setUint16(20, 1, true);  // Формат аудио (1 = PCM)
      view.setUint16(22, 1, true);  // Число каналов (1 = моно)
      view.setUint32(24, sampleRate, true); // Частота дискретизации
      view.setUint32(28, sampleRate * 2, true); // Байт в секунду (SampleRate * NumChannels * BitsPerSample/8)
      view.setUint16(32, 2, true);  // Байт на сэмпл (NumChannels * BitsPerSample/8)
      view.setUint16(34, 16, true); // Бит на сэмпл
      
      // "data" субчанк
      view.setUint8(36, 'd'.charCodeAt(0));
      view.setUint8(37, 'a'.charCodeAt(0));
      view.setUint8(38, 't'.charCodeAt(0));
      view.setUint8(39, 'a'.charCodeAt(0));
      
      view.setUint32(40, pcmBuffer.byteLength, true); // Размер данных
      
      // Объединяем заголовок и PCM данные
      const wavBuffer = new ArrayBuffer(wavHeader.byteLength + pcmBuffer.byteLength);
      const wavBytes = new Uint8Array(wavBuffer);
      
      wavBytes.set(new Uint8Array(wavHeader), 0);
      wavBytes.set(new Uint8Array(pcmBuffer), wavHeader.byteLength);
      
      return wavBuffer;
    }
    
    // Добавить аудио в очередь воспроизведения
    function addAudioToPlaybackQueue(audioBase64) {
      if (!audioBase64 || typeof audioBase64 !== 'string') return;
      
      // Добавляем аудио в очередь
      audioPlaybackQueue.push(audioBase64);
      
      // Если не запущено воспроизведение, запускаем
      if (!isPlayingAudio) {
        playNextAudio();
      }
    }
    
    // Воспроизведение следующего аудио в очереди
    function playNextAudio() {
      if (audioPlaybackQueue.length === 0) {
        isPlayingAudio = false;
        // Сбрасываем эффект говорения, когда все аудио воспроизведено
        voiceCircle.classList.remove('speaking');
        
        // Обновляем подсказку
        hintText.textContent = "Нажмите на круг, чтобы начать говорить";
        
        // Снова начинаем слушать
        if (!isListening && isConnected) {
          startListening();
        }
        return;
      }
      
      isPlayingAudio = true;
      
      // Активируем визуальное состояние говорения
      voiceCircle.classList.add('speaking');
      voiceCircle.classList.remove('listening');
      
      // Обновляем подсказку
      hintText.textContent = "Говорю...";
      
      const audioBase64 = audioPlaybackQueue.shift();
      
      try {
        // Декодируем Base64 в ArrayBuffer
        const audioData = base64ToArrayBuffer(audioBase64);
        
        // Проверяем размер данных
        if (audioData.byteLength === 0) {
          playNextAudio(); // Пропускаем пустой аудио-чанк
          return;
        }
        
        // Предполагаем, что данные в формате PCM16, конвертируем в WAV для воспроизведения
        const wavBuffer = createWavFromPcm(audioData);
        const blob = new Blob([wavBuffer], { type: 'audio/wav' });
        const audioUrl = URL.createObjectURL(blob);
        
        // Воспроизводим звук
        const audio = new Audio(audioUrl);
        
        audio.oncanplaythrough = function() {
          audio.play().catch(err => {
            log(`Ошибка при воспроизведении: ${err.message}`, "error");
            playNextAudio(); // В случае ошибки переходим к следующему аудио
          });
        };
        
        // После окончания воспроизведения
        audio.onended = function() {
          URL.revokeObjectURL(audioUrl);
          playNextAudio(); // Переходим к следующему аудио
        };
        
        // В случае ошибки
        audio.onerror = function() {
          URL.revokeObjectURL(audioUrl);
          playNextAudio(); // Переходим к следующему аудио
        };
      } catch (error) {
        log(`Ошибка воспроизведения аудио: ${error.message}`, "error");
        playNextAudio(); // В случае ошибки переходим к следующему аудио
      }
    }
    
    // Подключение к WebSocket серверу
    async function connectWebSocket() {
      try {
        loaderModal.classList.add('active');
        log("Подключение...");
        
        // Используем WebSocket-соединение с нашим сервером
        const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
        const wsUrl = `${protocol}//${window.location.host}/ws`;
        
        // Создаем новое WebSocket соединение
        websocket = new WebSocket(wsUrl);
        
        // Устанавливаем таймаут на открытие соединения
        const connectionTimeout = setTimeout(() => {
          log("Превышено время ожидания соединения", "error");
          websocket.close();
          loaderModal.classList.remove('active');
          addMessage("Не удалось подключиться к серверу. Пожалуйста, попробуйте позже.");
        }, 15000);
        
        websocket.onopen = function() {
          clearTimeout(connectionTimeout);
          log("Соединение установлено");
          isConnected = true;
          loaderModal.classList.remove('active');
          
          // В развернутом режиме показываем приветственное сообщение
          if (widgetMode === 'expanded' && messageHistory.length === 0) {
            setTimeout(() => {
              addMessage('Привет! Я голосовой ассистент WellcomeAI. Чем могу помочь?');
            }, 500);
          }
          
          // Автоматически начинаем слушать в развернутом режиме
          if (widgetMode === 'expanded') {
            startListening();
          }
        };
        
        websocket.onmessage = function(event) {
          try {
            const data = JSON.parse(event.data);
            
            // Обработка различных типов сообщений
            if (data.type === 'error') {
              log(`Ошибка: ${data.error ? data.error.message : 'Неизвестная ошибка'}`, "error");
            } 
            // Обработка текстового ответа
            else if (data.type === 'response.text.delta') {
              if (data.delta) {
                // Если это первая часть ответа, создаем новое сообщение
                if (!document.querySelector('.message.assistant:last-child') || 
                    document.querySelector('.message.assistant:last-child').dataset.complete === 'true') {
                  const msg = document.createElement('div');
                  msg.className = 'message assistant';
                  msg.textContent = data.delta;
                  messagesContainer.appendChild(msg);
                } else {
                  // Иначе добавляем к существующему
                  const lastMsg = document.querySelector('.message.assistant:last-child');
                  lastMsg.textContent += data.delta;
                }
                
                // Прокручиваем к последнему сообщению
                messagesContainer.scrollTop = messagesContainer.scrollHeight;
              }
            }
            // Текстовый ответ завершен
            else if (data.type === 'response.text.done') {
              if (data.text) {
                // Помечаем сообщение как завершенное
                const lastMsg = document.querySelector('.message.assistant:last-child');
                if (lastMsg) {
                  lastMsg.dataset.complete = 'true';
                  lastMsg.textContent = data.text;
                } else {
                  // Если сообщения нет, создаем новое
                  const msg = document.createElement('div');
                  msg.className = 'message assistant';
                  msg.textContent = data.text;
                  msg.dataset.complete = 'true';
                  messagesContainer.appendChild(msg);
                }
                
                // Прокручиваем к последнему сообщению
                messagesContainer.scrollTop = messagesContainer.scrollHeight;
              }
            }
            // Обработка транскрипции аудио пользователя
            else if (data.type === 'conversation.item.input_audio_transcription.completed') {
              if (data.transcript) {
                addMessage(data.transcript, true);
              }
            }
            // Обработка аудио ответа
            else if (data.type === 'response.audio.delta') {
              if (data.delta) {
                // Добавляем аудио чанк в буфер для накопления
                audioChunksBuffer.push(data.delta);
              }
            }
            // Аудиоответ завершен
            else if (data.type === 'response.audio.done') {
              if (audioChunksBuffer.length > 0) {
                const fullAudio = audioChunksBuffer.join('');
                // Добавляем в очередь воспроизведения
                addAudioToPlaybackQueue(fullAudio);
                // Очищаем буфер
                audioChunksBuffer = [];
              }
            }
            // Ответ завершен
            else if (data.type === 'response.done') {
              // Обновляем подсказку
              if (!isPlayingAudio) {
                hintText.textContent = "Нажмите на круг, чтобы начать говорить";
                
                // Начинаем снова слушать автоматически
                if (!isListening && !reconnecting) {
                  startListening();
                }
              }
            }
          } catch (error) {
            log(`Ошибка обработки сообщения: ${error.message}`, "error");
          }
        };
        
        websocket.onclose = function() {
          log("Соединение закрыто");
          isConnected = false;
          isListening = false;
          reconnecting = false;
          
          // Показываем сообщение пользователю
          addMessage("Соединение прервано. Переподключение...");
          
          // Сбрасываем состояние UI
          voiceCircle.classList.remove('listening');
          voiceCircle.classList.remove('speaking');
          hintText.textContent = "Подключение...";
          
          // Пытаемся переподключиться
          setTimeout(() => {
            connectWebSocket();
          }, 3000);
        };
        
        websocket.onerror = function(error) {
          log("Ошибка соединения", "error");
          addMessage("Ошибка соединения с сервером. Пожалуйста, попробуйте позже.");
        };
        
        return true;
      } catch (error) {
        log(`Ошибка при установке соединения: ${error.message}`, "error");
        loaderModal.classList.remove('active');
        addMessage("Не удалось подключиться к серверу. Пожалуйста, попробуйте позже.");
        return false;
      }
    }
    
    // Начало записи голоса
    async function startListening() {
      if (!isConnected || isPlayingAudio || reconnecting || isListening) {
        return;
      }
      
      isListening = true;
      log("Начало записи голоса");
      
      // Обновляем подсказку
      hintText.textContent = "Говорите после щелчка...";
      
      // Отправляем команду для очистки буфера ввода
      if (websocket && websocket.readyState === WebSocket.OPEN) {
        websocket.send(JSON.stringify({
          type: "input_audio_buffer.clear",
          event_id: `clear_${Date.now()}`
        }));
      }
      
      // Если аудио еще не инициализировано, делаем это
      if (!audioContext) {
        const initialized = await initAudio();
        if (!initialized) {
          isListening = false;
          hintText.textContent = "Не удалось получить доступ к микрофону";
          return;
        }
      } else if (audioContext.state === 'suspended') {
        // Возобновляем AudioContext если он был приостановлен
        try {
          await audioContext.resume();
        } catch (error) {
          log(`Ошибка при возобновлении AudioContext: ${error.message}`, "error");
          isListening = false;
          hintText.textContent = "Ошибка доступа к микрофону";
          return;
        }
      }
      
      // Сбрасываем флаги аудио данных
      hasAudioData = false;
      audioDataStartTime = 0;
      
      // Активируем визуальное состояние прослушивания если не воспроизводится аудио
      if (!isPlayingAudio) {
        voiceCircle.classList.add('listening');
        voiceCircle.classList.remove('speaking');
      }
    }
    
    // Инициализация
    async function init() {
      try {
        // Настраиваем обработчики событий
        robotButton.addEventListener('click', expandWidget);
        
        closeButton.addEventListener('click', collapseWidget);
        
        voiceCircle.addEventListener('click', function() {
          if (!isListening && !isPlayingAudio) {
            startListening();
          }
        });
        
        // Создаем WebSocket соединение
        await connectWebSocket();
      } catch (error) {
        console.error("Ошибка инициализации виджета:", error);
      }
    }
    
    // Запускаем инициализацию
    if (document.readyState === 'loading') {
      document.addEventListener('DOMContentLoaded', init);
    } else {
      init();
    }
  </script>
</body>
</html>
